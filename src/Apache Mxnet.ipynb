{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "mx.random.seed(42)\n",
    "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll configure the data iterator to feed examples in batches of 100. Keep in mind that each example is a 28x28 grayscale image and the corresponding label.\n",
    "\n",
    "Image batches are commonly represented by a 4-D array with shape (batch_size, num_channels, width, height). For the MNIST dataset, since the images are grayscale, there is only one color channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=100\n",
    "train=mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], size,shuffle=True)\n",
    "val_iter=mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach makes use of a Multilayer Perceptron to solve this problem. We’ll define the MLP using MXNet’s imperative approach.\n",
    "\n",
    "MLPs consist of several fully connected layers. A fully connected layer or FC layer for short, is one where each neuron in the layer is connected to every neuron in its preceding layer. From a linear algebra perspective, an FC layer applies an affine transform to the n x m input matrix X and outputs a matrix Y of size n x k, where k is the number of neurons in the FC layer. k is also referred to as the hidden size. The output Y is computed according to the equation Y = W X + b. The FC layer has two learnable parameters, the m x k weight matrix W and the m x 1 bias vector b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "data = mx.sym.flatten(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1  = mx.sym.FullyConnected(data=data, num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2  = mx.sym.FullyConnected(data=act1, num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, act_type=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc3  = mx.sym.FullyConnected(data=act2, num_hidden=10)\n",
    "# Softmax with cross entropy loss\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 62277.34 samples/sec\taccuracy=0.107525\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 65108.83 samples/sec\taccuracy=0.113200\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 65534.46 samples/sec\taccuracy=0.111300\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 63459.77 samples/sec\taccuracy=0.114400\n",
      "INFO:root:Epoch[0] Batch [500]\tSpeed: 63865.03 samples/sec\taccuracy=0.135500\n",
      "INFO:root:Epoch[0] Train-accuracy=0.218889\n",
      "INFO:root:Epoch[0] Time cost=0.952\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.290300\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 61513.32 samples/sec\taccuracy=0.452772\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 63460.83 samples/sec\taccuracy=0.695200\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 53051.63 samples/sec\taccuracy=0.779100\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 54493.21 samples/sec\taccuracy=0.810700\n",
      "INFO:root:Epoch[1] Batch [500]\tSpeed: 56648.24 samples/sec\taccuracy=0.828600\n",
      "INFO:root:Epoch[1] Train-accuracy=0.844343\n",
      "INFO:root:Epoch[1] Time cost=1.066\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.857200\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 56330.08 samples/sec\taccuracy=0.856535\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 60768.08 samples/sec\taccuracy=0.869400\n",
      "INFO:root:Epoch[2] Batch [300]\tSpeed: 50897.55 samples/sec\taccuracy=0.886900\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 51684.22 samples/sec\taccuracy=0.893900\n",
      "INFO:root:Epoch[2] Batch [500]\tSpeed: 55396.02 samples/sec\taccuracy=0.905400\n",
      "INFO:root:Epoch[2] Train-accuracy=0.913939\n",
      "INFO:root:Epoch[2] Time cost=1.086\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.914800\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 62278.08 samples/sec\taccuracy=0.915149\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 61893.38 samples/sec\taccuracy=0.923400\n",
      "INFO:root:Epoch[3] Batch [300]\tSpeed: 63460.73 samples/sec\taccuracy=0.929800\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 63460.35 samples/sec\taccuracy=0.927600\n",
      "INFO:root:Epoch[3] Batch [500]\tSpeed: 61893.93 samples/sec\taccuracy=0.934900\n",
      "INFO:root:Epoch[3] Train-accuracy=0.939394\n",
      "INFO:root:Epoch[3] Time cost=0.962\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.940700\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 55091.80 samples/sec\taccuracy=0.937525\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 50133.74 samples/sec\taccuracy=0.946200\n",
      "INFO:root:Epoch[4] Batch [300]\tSpeed: 57625.39 samples/sec\taccuracy=0.946200\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 51156.91 samples/sec\taccuracy=0.943200\n",
      "INFO:root:Epoch[4] Batch [500]\tSpeed: 50385.90 samples/sec\taccuracy=0.948500\n",
      "INFO:root:Epoch[4] Train-accuracy=0.951515\n",
      "INFO:root:Epoch[4] Time cost=1.128\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.953600\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 52496.39 samples/sec\taccuracy=0.949406\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 56015.55 samples/sec\taccuracy=0.956000\n",
      "INFO:root:Epoch[5] Batch [300]\tSpeed: 62278.08 samples/sec\taccuracy=0.956900\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 61514.58 samples/sec\taccuracy=0.956100\n",
      "INFO:root:Epoch[5] Batch [500]\tSpeed: 60402.10 samples/sec\taccuracy=0.958500\n",
      "INFO:root:Epoch[5] Train-accuracy=0.961111\n",
      "INFO:root:Epoch[5] Time cost=1.038\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.960700\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 60407.06 samples/sec\taccuracy=0.959109\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 58980.50 samples/sec\taccuracy=0.962300\n",
      "INFO:root:Epoch[6] Batch [300]\tSpeed: 51419.44 samples/sec\taccuracy=0.964100\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 56015.40 samples/sec\taccuracy=0.963700\n",
      "INFO:root:Epoch[6] Batch [500]\tSpeed: 56012.93 samples/sec\taccuracy=0.967300\n",
      "INFO:root:Epoch[6] Train-accuracy=0.968485\n",
      "INFO:root:Epoch[6] Time cost=1.083\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.964400\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 55704.13 samples/sec\taccuracy=0.965050\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 54790.90 samples/sec\taccuracy=0.967800\n",
      "INFO:root:Epoch[7] Batch [300]\tSpeed: 60402.10 samples/sec\taccuracy=0.969100\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 59329.91 samples/sec\taccuracy=0.969300\n",
      "INFO:root:Epoch[7] Batch [500]\tSpeed: 60768.26 samples/sec\taccuracy=0.972000\n",
      "INFO:root:Epoch[7] Train-accuracy=0.973434\n",
      "INFO:root:Epoch[7] Time cost=1.042\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.966500\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 52772.22 samples/sec\taccuracy=0.970891\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 52772.35 samples/sec\taccuracy=0.970800\n",
      "INFO:root:Epoch[8] Batch [300]\tSpeed: 47073.91 samples/sec\taccuracy=0.973200\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 50385.48 samples/sec\taccuracy=0.973700\n",
      "INFO:root:Epoch[8] Batch [500]\tSpeed: 53051.63 samples/sec\taccuracy=0.975400\n",
      "INFO:root:Epoch[8] Train-accuracy=0.977475\n",
      "INFO:root:Epoch[8] Time cost=1.180\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.968700\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 53051.29 samples/sec\taccuracy=0.975050\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 52222.59 samples/sec\taccuracy=0.975300\n",
      "INFO:root:Epoch[9] Batch [300]\tSpeed: 57295.95 samples/sec\taccuracy=0.978100\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 52222.78 samples/sec\taccuracy=0.977000\n",
      "INFO:root:Epoch[9] Batch [500]\tSpeed: 51952.07 samples/sec\taccuracy=0.977900\n",
      "INFO:root:Epoch[9] Train-accuracy=0.979596\n",
      "INFO:root:Epoch[9] Time cost=1.117\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.970100\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\n",
    "# create a trainable module on compute context\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=ctx)\n",
    "mlp_model.fit(train,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "              optimizer='sgd',  # use SGD to train\n",
    "              optimizer_params={'learning_rate':0.1},  # use fixed learning rate\n",
    "              eval_metric='acc',  # report accuracy during training\n",
    "              batch_end_callback = mx.callback.Speedometer(size, 100), # output progress for each 100 data batches\n",
    "              num_epoch=10)  # train for at most 10 dataset passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], None, size)\n",
    "prob = mlp_model.predict(test_iter)\n",
    "assert prob.shape == (10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalMetric: {'accuracy': 0.9701}\n"
     ]
    }
   ],
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], size)\n",
    "# predict accuracy of mlp\n",
    "acc = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter, acc)\n",
    "print(acc)\n",
    "assert acc.get()[1] > 0.96, \"Achieved accuracy (%f) is lower than expected (0.96)\" % acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "# first conv layer\n",
    "conv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# second conv layer\n",
    "conv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=pool2)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "# second fullc\n",
    "fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n",
    "# softmax loss\n",
    "lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 1101.60 samples/sec\taccuracy=0.107327\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 1106.22 samples/sec\taccuracy=0.113200\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 856.91 samples/sec\taccuracy=0.111300\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 898.94 samples/sec\taccuracy=0.114400\n",
      "INFO:root:Epoch[0] Batch [500]\tSpeed: 895.57 samples/sec\taccuracy=0.107500\n",
      "INFO:root:Epoch[0] Train-accuracy=0.116869\n",
      "INFO:root:Epoch[0] Time cost=63.378\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.113500\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 865.64 samples/sec\taccuracy=0.178218\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 828.52 samples/sec\taccuracy=0.659200\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 850.66 samples/sec\taccuracy=0.867000\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 861.26 samples/sec\taccuracy=0.903700\n",
      "INFO:root:Epoch[1] Batch [500]\tSpeed: 855.82 samples/sec\taccuracy=0.924200\n",
      "INFO:root:Epoch[1] Train-accuracy=0.937677\n",
      "INFO:root:Epoch[1] Time cost=70.732\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.947400\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 774.92 samples/sec\taccuracy=0.948218\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 820.59 samples/sec\taccuracy=0.955100\n",
      "INFO:root:Epoch[2] Batch [300]\tSpeed: 771.58 samples/sec\taccuracy=0.960200\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 809.72 samples/sec\taccuracy=0.960600\n",
      "INFO:root:Epoch[2] Batch [500]\tSpeed: 780.23 samples/sec\taccuracy=0.965500\n",
      "INFO:root:Epoch[2] Train-accuracy=0.967677\n",
      "INFO:root:Epoch[2] Time cost=75.340\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.973400\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 830.99 samples/sec\taccuracy=0.971287\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 827.43 samples/sec\taccuracy=0.973200\n",
      "INFO:root:Epoch[3] Batch [300]\tSpeed: 830.65 samples/sec\taccuracy=0.975700\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 821.73 samples/sec\taccuracy=0.975200\n",
      "INFO:root:Epoch[3] Batch [500]\tSpeed: 822.74 samples/sec\taccuracy=0.977100\n",
      "INFO:root:Epoch[3] Train-accuracy=0.979192\n",
      "INFO:root:Epoch[3] Time cost=72.625\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.979500\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 809.98 samples/sec\taccuracy=0.978119\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 806.59 samples/sec\taccuracy=0.980500\n",
      "INFO:root:Epoch[4] Batch [300]\tSpeed: 800.54 samples/sec\taccuracy=0.981900\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 802.20 samples/sec\taccuracy=0.982000\n",
      "INFO:root:Epoch[4] Batch [500]\tSpeed: 801.41 samples/sec\taccuracy=0.982600\n",
      "INFO:root:Epoch[4] Train-accuracy=0.984343\n",
      "INFO:root:Epoch[4] Time cost=74.545\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.982700\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 797.61 samples/sec\taccuracy=0.982970\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 795.33 samples/sec\taccuracy=0.984200\n",
      "INFO:root:Epoch[5] Batch [300]\tSpeed: 728.74 samples/sec\taccuracy=0.985800\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 778.59 samples/sec\taccuracy=0.985300\n",
      "INFO:root:Epoch[5] Batch [500]\tSpeed: 789.82 samples/sec\taccuracy=0.985300\n",
      "INFO:root:Epoch[5] Train-accuracy=0.986869\n",
      "INFO:root:Epoch[5] Time cost=77.607\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.985600\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 768.80 samples/sec\taccuracy=0.985941\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 771.53 samples/sec\taccuracy=0.987600\n",
      "INFO:root:Epoch[6] Batch [300]\tSpeed: 772.30 samples/sec\taccuracy=0.988700\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 761.74 samples/sec\taccuracy=0.987200\n",
      "INFO:root:Epoch[6] Batch [500]\tSpeed: 773.73 samples/sec\taccuracy=0.987600\n",
      "INFO:root:Epoch[6] Train-accuracy=0.988283\n",
      "INFO:root:Epoch[6] Time cost=78.162\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.987300\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 752.31 samples/sec\taccuracy=0.988119\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 755.25 samples/sec\taccuracy=0.989800\n",
      "INFO:root:Epoch[7] Batch [300]\tSpeed: 746.82 samples/sec\taccuracy=0.990500\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 757.19 samples/sec\taccuracy=0.988900\n",
      "INFO:root:Epoch[7] Batch [500]\tSpeed: 777.21 samples/sec\taccuracy=0.988900\n",
      "INFO:root:Epoch[7] Train-accuracy=0.991010\n",
      "INFO:root:Epoch[7] Time cost=78.959\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.988200\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 762.26 samples/sec\taccuracy=0.990000\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 756.74 samples/sec\taccuracy=0.991200\n",
      "INFO:root:Epoch[8] Batch [300]\tSpeed: 789.07 samples/sec\taccuracy=0.991700\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 802.72 samples/sec\taccuracy=0.990700\n",
      "INFO:root:Epoch[8] Batch [500]\tSpeed: 794.83 samples/sec\taccuracy=0.990100\n",
      "INFO:root:Epoch[8] Train-accuracy=0.992626\n",
      "INFO:root:Epoch[8] Time cost=76.671\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.988900\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 782.42 samples/sec\taccuracy=0.991089\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 769.63 samples/sec\taccuracy=0.992300\n",
      "INFO:root:Epoch[9] Batch [300]\tSpeed: 722.91 samples/sec\taccuracy=0.992500\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 743.11 samples/sec\taccuracy=0.992200\n",
      "INFO:root:Epoch[9] Batch [500]\tSpeed: 783.16 samples/sec\taccuracy=0.991700\n",
      "INFO:root:Epoch[9] Train-accuracy=0.993232\n",
      "INFO:root:Epoch[9] Time cost=78.994\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.989500\n"
     ]
    }
   ],
   "source": [
    "lenet_model = mx.mod.Module(symbol=lenet, context=ctx)\n",
    "# train with the same\n",
    "lenet_model.fit(train,\n",
    "                eval_data=val_iter,\n",
    "                optimizer='sgd',\n",
    "                optimizer_params={'learning_rate':0.1},\n",
    "                eval_metric='acc',\n",
    "                batch_end_callback = mx.callback.Speedometer(size, 100),\n",
    "                num_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalMetric: {'accuracy': 0.9895}\n"
     ]
    }
   ],
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], None, size)\n",
    "prob = lenet_model.predict(test_iter)\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], size)\n",
    "# predict accuracy for lenet\n",
    "acc = mx.metric.Accuracy()\n",
    "lenet_model.score(test_iter, acc)\n",
    "print(acc)\n",
    "assert acc.get()[1] > 0.98, \"Achieved accuracy (%f) is lower than expected (0.98)\" % acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
